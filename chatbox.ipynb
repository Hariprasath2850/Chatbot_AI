{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "வணக்கம்! தமிழில் உங்கள் செயல்பாடுகளை உள்ளிடவும்.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample correction function (replace with your actual model)\n",
    "def correct_sentence(sentence):\n",
    "    # Placeholder correction function\n",
    "    return sentence.upper()\n",
    "\n",
    "# Tokenize input text\n",
    "def tokenize_input(text):\n",
    "    return word_tokenize(text, language='tamil')\n",
    "\n",
    "def main():\n",
    "    print(\"வணக்கம்! தமிழில் உங்கள் செயல்பாடுகளை உள்ளிடவும்.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"உள்ளிடவும்: \")\n",
    "\n",
    "        if user_input.lower() == 'நீங்கள் வெற்றிகரமாக முடிந்தது':\n",
    "            print(\"நன்றி! வெற்றிகரமாக முடிந்து விட்டீர்கள்.\")\n",
    "            break\n",
    "\n",
    "        corrected_sentence = correct_sentence(user_input)\n",
    "        print(\"திருத்தப்பட்ட செய்தி: \", corrected_sentence)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement PyTamil (from versions: none)\n",
      "ERROR: No matching distribution found for PyTamil\n"
     ]
    }
   ],
   "source": [
    "pip install PyTamil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tamil_words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspellchecker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpellChecker\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load a simple dataset of Tamil words for basic spell checking\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtamil_words.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m     tamil_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines())\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect_tamil_text\u001b[39m(input_text):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tamil_words.txt'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Load a simple dataset of Tamil words for basic spell checking\n",
    "with open(\"tamil_words.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tamil_words = set(f.read().splitlines())\n",
    "\n",
    "def correct_tamil_text(input_text):\n",
    "    spell = SpellChecker(language=None)  # Use default language (English)\n",
    "    # Split the input text into words and correct misspelled ones\n",
    "    corrected_words = [spell.correction(word) if word not in tamil_words else word for word in input_text.split()]\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def main():\n",
    "    st.title(\"Tamil Chatbox\")\n",
    "\n",
    "    user_input = st.text_input(\"உள்ளிடவும்: \")\n",
    "\n",
    "    if user_input:\n",
    "        corrected_text = correct_tamil_text(user_input)\n",
    "        st.text(\"திருத்தப்பட்ட செய்தி: \" + corrected_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 17:17:03.153 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\harip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "def correct_tamil_text(input_text):\n",
    "    spell = SpellChecker(language='ta')  # Set language to Tamil\n",
    "    corrected_words = [spell.correction(word) for word in input_text.split()]\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def main():\n",
    "    st.title(\"Tamil Chatbox\")\n",
    "\n",
    "    user_input = st.text_input(\"உள்ளிடவும்: \")\n",
    "\n",
    "    if user_input:\n",
    "        corrected_text = correct_tamil_text(user_input)\n",
    "        st.text(\"திருத்தப்பட்ட செய்தி: \" + corrected_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def correct_tamil_statement(input_statement):\n",
    "    # Tokenize the input statement\n",
    "    words = word_tokenize(input_statement)\n",
    "\n",
    "    # Error correction logic (simplified)\n",
    "    corrected_statement = tamil_data.get(input_statement, \"No correction found.\")\n",
    "    \n",
    "    return corrected_statement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Statement: என் பள்ளி பகுதியில் என் மகிழ்ச்சியின் குறிகள் கேட்டன.\n",
      "Corrected Statement: No correction found.\n"
     ]
    }
   ],
   "source": [
    "# Test the error correction function\n",
    "input_statement = \"என் பள்ளி பகுதியில் என் மகிழ்ச்சியின் குறிகள் கேட்டன.\"\n",
    "corrected_output = correct_tamil_statement(input_statement)\n",
    "print(\"Input Statement:\", input_statement)\n",
    "print(\"Corrected Statement:\", corrected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "def correct_tamil_text(input_text):\n",
    "    spell = SpellChecker(language='ta')  # Set language to Tamil\n",
    "    corrected_words = []\n",
    "    corrections = {}\n",
    "\n",
    "    for word in input_text.split():\n",
    "        corrected_word = spell.correction(word)\n",
    "        if corrected_word != word:\n",
    "            corrections[word] = corrected_word\n",
    "            corrected_words.append(f\"**{corrected_word}**\")\n",
    "        else:\n",
    "            corrected_words.append(word)\n",
    "\n",
    "    corrected_text = \" \".join(corrected_words)\n",
    "    return corrected_text, corrections\n",
    "\n",
    "def main():\n",
    "    st.title(\"Tamil Chatbox\")\n",
    "\n",
    "    user_input = st.text_input(\"உள்ளிடவும்: \")\n",
    "\n",
    "    if user_input:\n",
    "        corrected_text, corrections = correct_tamil_text(user_input)\n",
    "        st.write(\"திருத்தப்பட்ட செய்தி:\")\n",
    "        st.write(f\"உங்கள் அடிப்படை வாக்குமூலம்: **{user_input}**\")\n",
    "        st.write(f\"திருத்தப்பட்ட வாக்குமூலம்: {corrected_text}\")\n",
    "\n",
    "        if corrections:\n",
    "            st.write(\"தவறான சொற்கள்:\")\n",
    "            for original, corrected in corrections.items():\n",
    "                st.write(f\"{original} -> {corrected}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the language generation pipeline\u001b[39;00m\n\u001b[0;32m      4\u001b[0m generator \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-neo-2.7B\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     logging,\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     51\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.utils'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the language generation pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\")\n",
    "\n",
    "def correct_tamil_statement(input_text):\n",
    "    # You may need to preprocess the input text before passing it to the model\n",
    "    # For example, tokenization, encoding, etc.\n",
    "    # Here, we directly pass the input text to the model for demonstration purposes\n",
    "    corrected_statement = generator(input_text, max_length=100, num_return_sequences=1, do_sample=True)[0]['generated_text']\n",
    "    return corrected_statement\n",
    "\n",
    "# Example usage\n",
    "input_statement = \"எனக்கு வேலை வேண்டும், ஆனா என் பரிதாபம் பற்றி பேச வேண்டும்.\"\n",
    "corrected_statement = correct_tamil_statement(input_statement)\n",
    "print(\"Corrected Statement:\")\n",
    "print(corrected_statement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
